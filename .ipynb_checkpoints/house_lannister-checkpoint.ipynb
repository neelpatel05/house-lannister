{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "from random import shuffle\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Euron Greyjoy 26\n",
      "Jon Snow 103\n",
      "Cersei Lannister 206\n",
      "Qyburn 33\n",
      "Daenerys Targaryen 103\n",
      "Ser Davos 23\n",
      "Samwell Tarly 20\n",
      "Arya Stark 26\n",
      "the hound 32\n",
      "Peytr Baelish 18\n",
      "Unknown - not a face 21\n",
      "Theon Greyjoy 56\n",
      "Jaime Lannister 113\n",
      "Sansa Stark 31\n",
      "Brienne of Tarth 26\n",
      "Bronn 33\n",
      "Podrick 28\n",
      "Tyrion Lannister 101\n",
      "Unknown Person 195\n",
      "Jorah Mormont 33\n",
      "Missandei 34\n",
      "Varys 35\n"
     ]
    }
   ],
   "source": [
    "for i in os.listdir(\"Dataset\"):\n",
    "    print(os.path.basename(\"Dataset/\"+i),len(os.listdir(\"Dataset/\"+i)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"Dataset-new/train\")\n",
    "os.makedirs(\"Dataset-new/test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22/22 [00:00<00:00, 131.68it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(os.listdir(\"Dataset\")):\n",
    "    if i==\"Cersei Lannister\" or i==\"Jaime Lannister\" or i==\"Tyrion Lannister\":\n",
    "        os.makedirs(\"Dataset-new/train/\"+i)\n",
    "        os.makedirs(\"Dataset-new/test/\"+i)\n",
    "        for j in os.listdir(\"Dataset/\"+i)[:80]:\n",
    "            shutil.copy(\"Dataset/\"+i+\"/\"+j,\"Dataset-new/train/\"+i)\n",
    "        for j in os.listdir(\"Dataset/\"+i)[80:100]:\n",
    "            shutil.copy(\"Dataset/\"+i+\"/\"+j,\"Dataset-new/test/\"+i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data\n",
      "Cersei Lannister 80\n",
      "Jaime Lannister 80\n",
      "Tyrion Lannister 80\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Data\")\n",
    "for i in os.listdir(\"Dataset-new/train\"):\n",
    "    print(os.path.basename(\"Dataset-new/train/\"+i),len(os.listdir(\"Dataset-new/train/\"+i)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Data\n",
      "Cersei Lannister 20\n",
      "Jaime Lannister 20\n",
      "Tyrion Lannister 20\n"
     ]
    }
   ],
   "source": [
    "print(\"Testing Data\")\n",
    "for i in os.listdir(\"Dataset-new/test\"):\n",
    "    print(os.path.basename(\"Dataset-new/test/\"+i),len(os.listdir(\"Dataset-new/test/\"+i)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DIR = \"Dataset-new/train\"\n",
    "VALIDATION_DIR = \"Dataset-new/test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 240 images belonging to 3 classes.\n",
      "Found 60 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "IMAGE_SIZE_NEW = 96\n",
    "BATCH_SIZE = 10\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=False\n",
    ")\n",
    "\n",
    "validation_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=False\n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    TRAIN_DIR,\n",
    "    target_size = (IMAGE_SIZE_NEW, IMAGE_SIZE_NEW),\n",
    "    batch_size = BATCH_SIZE,\n",
    ")\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    VALIDATION_DIR,\n",
    "    target_size = (IMAGE_SIZE_NEW, IMAGE_SIZE_NEW),\n",
    "    batch_size = BATCH_SIZE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 94, 94, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 47, 47, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 46, 46, 64)        8256      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 23, 23, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 23, 23, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 33856)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               4333696   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 4,343,235\n",
      "Trainable params: 4,343,235\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32,kernel_size=(3,3),activation='relu',input_shape=(IMAGE_SIZE_NEW,IMAGE_SIZE_NEW,3)))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Conv2D(64,kernel_size=(2,2),activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128,activation='relu'))\n",
    "model.add(Dense(3,activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      " 53/240 [=====>........................] - ETA: 39s - loss: 0.8454 - acc: 0.6000"
     ]
    }
   ],
   "source": [
    "steps_per_epoch = train_generator.n \n",
    "validation_steps = validation_generator.n\n",
    "\n",
    "history=model.fit_generator(train_generator,\n",
    "                            epochs=3,\n",
    "                            steps_per_epoch=steps_per_epoch,\n",
    "                            validation_data=validation_generator,\n",
    "                            validation_steps=validation_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
